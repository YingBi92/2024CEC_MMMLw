
<!doctype html>
<html>
<head>
<style>  
body{ 
    margin:0 auto; 
    float:right;
    margin-right:15%;
    margin-left:15%;
    font-family:verdana;
    font-size=4;
    line-height: 150%;
}
h1 {
    line-height: 1.2em; /* or whatever... */
}
li:not(:last-child) {
    margin-bottom: 3px; 
    padding:5px   
} 
</style>
<title> Workshop on Multimodal Optimization for Machine Learning </title>
</head> 

<body>  

 
<!--<div style="background-color:#FFFFFF;height:2000px;width:20%;float:left;">     
</div>
<div style="background-color:#FFFFFF;height:2000px;width:20%;float:right;">     
</div>-->

<p>&nbsp;</p>
<h3> <font color="3399ff" size=6><b>Call for Papers</b></font></h3>
<p></p>
<p></p>

<center>
<h1>Workshop on <font color="#0000FF"> <b> Multimodal Optimization for Machine Learning </b></font></h1> 



<p>2024 IEEE WCCI, Japan</p>    
</center>


<p></p>
<p></p>
<p></p> 

<p>Duration: Half-day</p> 

  
<p>Machine learning is an important research area and has become increasingly popular in various fields, such as security, engineering, sciences, finance, marketing, healthcare, and marketing. Machine learning covers a wide range of supervised, unsupervised, and semisupervised tasks such as regression, classification, clustering, ensemble learning, and feature selection. Many issues or challenges, such as generalizability, interpretability, robustness, security, privacy, and data scarcity, require the development of new machine learning algorithms that can provide effective solutions.</p> 

<p>Evolutionary Computation (EC) includes a family of nature-inspired population-based algorithms/techniques, including Genetic Algorithms (GAs), Genetic Programming (GP). Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO), Differential Evolution (DE), Evolutionary Multi-Objective Optimization (EMO). EC techniques have promising global search ability to find high-quality solutions to problems without requiring rich domain knowledge and differential objective functions. EC techniques have been widely applied for many tasks in the fields of engineering, economics, finance, manufacturing, management, etc.</p>

<p> Multimodal optimization is a subfield of EC, which aims to develop veracious EC techniques with powerful search ability to find multiple (nearly) optimal solutions in a single run for an optimization problem. In many real-world scenarios, it is necessary to have multiple solutions with similar performance for better use. To find multiple solutions, many new strategies have been proposed in EC methods to enhance their global and local search ability, such as niching, parallel computing, multi-population, multitasking, etc.</p> 

<p>In machine learning, there are many optimization problems requiring powerful search techniques. EC methods have also been widely applied to machine learning problems, including feature selection, ensemble combination, classifier generation, and parameter optimization. However, due to the different requirements in terms of model accuracy. complexity, interpretability, etc, it is valuable to find multiple solutions in machine learning, which are promising for future use. For example, in feature selection, if the methods can find multiple optimal feature subsets, the end users will have more choices in terms of which subset is more applicable based on different criteria. However, the potential of multimodal optimization for machine learning has not been comprehensively explored. It is necessary to develop new multimodal optimization approaches for machine learning.</p>

 
<p>&nbsp;</p>
<h3><font color="#0000FF">Aim and Scope:</font></h3> 

<p> The theme of this workshop is the use of multimodal optimization for machine learning, covering ALL different evolutionary computation-based techniques paradigms for machine learning.</p>

<p> The aim of this workshop is to investigate both the new theories and applications in different multimodal optimization paradigms for machine learning. This workshop will bring together researchers and practitioners from around the world to discuss the latest advances in the field and will act as a major forum for the presentation of recent research.</p>

<p> Authors are invited to submit their original and unpublished work to this workshop. Topics related to all aspects of multimodal optimization for machine learning, such as theories, algorithms, systems and applications, are welcome. </p>

 
<p>&nbsp;</p>
<h3><font color="#0000FF">Topics of interest include but are not limited to:</font></h3>
</p>


<ul>
<li>Particle swarm optimization</li>
<li>Genetic algorithms</li>
<li>Genetic programming</li>
<li>Differential evolution</li>
<li>Multi-objective optimization</li>
<li>Multimodal multi-objective optimization</li> 
<li>Constrained multimodal optimization</li>
<li>Constrained multimodal multi-objective optimization</li>
<li>Dynamic multimodal optimization</li>
<li>Expensive constrained multimodal optimization</li>
<li>Expensive multimodal optimization</li>
<li>Multitask optimization</li>
<li>Surrogate-assisted multimodal optimization</li>
<li>Feature selection</li>
<li> Instance selection</li>
<li> Feature construction</li>
<li>Feature extraction</li>
<li> Classification</li>
<li> Regression</li>
<li> Clustering</li>
<li>Few-shot learning</li> 
<li>Deep learning</li>
<li>Ensemble learning</li>
<li>Neural networks</li>
<li>Support vector machines</li>
<li>Decision trees</li>
<li>Random forests</li>
<li>Text classification</li>
<li> Real-world multimodal applications</li>
</ul>   
</p>

<p>&nbsp;</p>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Workshop on Multimodal Optimization for Machine Learning </title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        h2 {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <h3><font color="#0000FF">Workshop on Multimodal Optimization for Machine Learning </font></h3>
    <p><b>4 July 14:20-18:40</b></p>
    <table>
        <tr>
            <th>Time</th>
            <th></th>
            <th>Length</th>
            <th>Speaker</th>
            <th>Title</th>
        </tr>
        <tr>
            <td class="nowrap">14:20-14:30</td>
            <td>Opening</td>
            <td>10 mins</td>
            <td></td>
            
        </tr>
        <tr>
            <td>14:30-15:25</td>
            <td>Invited talk</td>
            <td>55 mins</td>
            <td>P.N. Suganthan</td>
            <td>Evolutionary Algorithms for Machine Learning: Some applications, opportunities and potential challenges</td>
        </tr>
        <tr>
            <td>15:25-16:20</td>
            <td>Invited talk</td>
            <td>55 mins</td>
            <td>Amir H Gandomi</td>
            <td>Evolutionary Machine Learning and Optimisation in Action</td>
        </tr>
         <tr>
            <td></td>
            <td>Tea break</td>
     
        </tr>

        <tr>
            <td>16:40-17:10</td>
            <td>Invited talk</td>
            <td>30 mins</td>
            <td>Xilu Wang</td>
            <td>Heterogeneous multi-objective optimization</td>
        </tr>
        <tr>
            <td>17:10-17:40</td>
            <td>Invited talk</td>
            <td>30 mins</td>
            <td>Songbai Liu</td>
            <td>Learning Improvement Representations to Accelerate Evolutionary Complex Multiobjective Optimization</td>
        </tr>
        <tr>
            <td>17:40-18:10</td>
            <td>Invited talk</td>
            <td>30 mins</td>
            <td>Peng Wang</td>
            <td>Solving Multi-solution Problems in Machine Learning via Evolutionary Computation</td>
        </tr>
        <tr>
            <td>18:10-18:40</td>
            <td>Invited talk</td>
            <td>30 mins</td>
            <td>Weifeng Guo</td>
            <td>Evolutionary Optimisation for Medicine</td>
        </tr>
    </table>
</body>

<p></p>
<div style="height: 20px;"></div>
<p><b>Tilte:</b>Evolutionary Algorithms for Machine Learning: Some applications, opportunities and potential challenges</p>
<p><b>Abstract: </b>Machine learning algorithms frequently involves optimization problems. Evolutionary algorithms have been investigated and applied to solve a number of practical problems. Therefore, it is natural to apply evolutionary algorithms to solve some selected machine learning problems. This talk will first briefly introduce some basic evolutionary algorithms. Subsequently, these algorithms will be applied to solve some machine learning problems such as clustering, feature selection, classification and so on. The talk will highlight potential challenges and how to overcome them. Â </p>
<p><b>Bio: </b>Ponnuthurai Nagaratnam Suganthan(Fellow, IEEE) received the B.A. and M.A. degrees in electrical and information engineering from the University of Cambridge, U.K., in 1990, 1992, and 1994, respectively. He received the Honorary Doctorate (i.e., Doctor Honoris Causa) degree from University of Maribor, Maribor, Slovenia, in 2020. After completing the Ph.D. research in 1995, he served as a Predoctoral Research Assistant with the Department of Electrical Engineering, The University of Sydney, Australia, from 1995 to 1996, and a Lecturer with the Department of Computer Science and Electrical Engineering, University of Queensland, Australia, from 1996 to 1999. Since August 2022, he has been with KINDI Center for Computing Research, Qatar University, Qatar, as a Research Professor. His research interests include randomization-based learning methods, swarm and evolutionary algorithms, pattern recognition, deep learning and applications of swarm, evolutionary and machine learning algorithms. Dr. Suganthanâs coauthored SaDE paper (published in April 2009) won theâIEEE Transactions on Evolutionary Computation Outstanding Paper Awardâ in 2012. He was an Editorial Board Member of the Evolutionary Computation Journal, MIT Press from 2013 to 2018. He is/was an Associate Editor of the Applied Soft Computing (Elsevier) since 2018, Neurocomputing (Elsevier) since 2018, IEEE Transactions on Cybernetics from 2012 to 2018, IEEE Transactions on Evolutionary Computation from 2005 to 2021, Information Sciences (Elsevier) since 2009, Pattern Recognition (Elsevier) since 2001, and IEEE Transactins on SMC: Systems since 2020. He is a Founding Co Editor in Chief of Swarm and Evolutionary Computation since 2010, a SCI Indexed Journal (Elsevier). He was selected as one of the highly cited researchers by Thomson Reuters Science Citations yearly from 2015 to 2022 in computer science. He served as the General Chair of the IEEE SSCI 2013. He was an Elected AdCom Member of the IEEE Computational Intelligence Society from 2014 to 2016. He was an IEEE CIS Distinguished Lecturer from 2018 to 2021.</p>

<div style="height: 20px;"></div>
<p><b>Tilte:</b>Evolutionary Machine Learning and Optimisation in Action</p>
<p><b>Abstract: </b>This talk focuses on the synergistic use of evolutionary optimisation and machine learning techniques to enhance problem-solving in various domains. I will begin with an introduction to genetic programming (GP), an automated learning approach that exemplifies applied evolutionary machine learning. This segment will highlight recent advancements and applications, particularly in big data analytics and modeling, showcasing how GP can be effectively utilized to refine predictive accuracy and model robustness. Further, the presentation will cover the broader applications of evolutionary computation in optimizing complex and nonlinear systems across different fields, such as engineering. I will discuss the superior capabilities of these algorithms over traditional methods, particularly their adaptability and efficacy in handling large-scale and multi-objective optimization problems. Lastly, I will present case studies from my research, demonstrating the successful application of evolutionary in various scenarios. The discussion will also explore adaptable heuristics within evolutionary computation, which significantly enhance optimization outcomes, offering practical insights into their deployment in real-world settings.</p>
<p><b>Bio: </b>Bio: Amir H. Gandomi is a Professor of Data Science and an ARC DECRA Fellow at the Faculty of Engineering & Information Technology, University of Technology Sydney. He is also affiliated with Obuda University, Budapest, as a Distinguished Professor. Prior to joining UTS, Prof. Gandomi was an Assistant Professor at the Stevens Institute of Technology and a distinguished research fellow at BEACON Center, Michigan State University. Prof. Gandomi has published over three hundred journal papers and 12 books which collectively have been cited 50,000+ times. He has been named as one of the most influential scientific minds and received the Highly Cited Researcher award (top 1% publications and 0.1% researchers) from Web of Science for six times. In a recent study at Stanford University, released by Elsevier, Prof Amir H Gandomi is ranked 28th most impactful researcher in the AI and Image Processing subfield in 2022! He also ranked 17th in GP bibliography among more than 15,000 researchers. He has received multiple prestigious awards for his research excellence and impact, such as the 2023 Achenbach Medal and the 2022 Walter L. Huber Prize, the highest-level mid-career research award in all areas of civil engineering. He has served as associate editor, editor, and guest editor in several prestigious journals, such as AE of IEEE Networks and IEEE IoTJ. Prof Gandomi is active in delivering keynotes and invited talks. His research interests are global optimisation and (big) data analytics using machine learning and evolutionary computations in particular.
</p>

<div style="height: 20px;"></div>
<p><b>Tilte:</b>Heterogeneous multi-objective optimization</p>
<p><b>Abstract: </b>Multiobjective optimization problems whose objectives have different evaluation costs are commonly seen in the real world. Such problems are now known as multiobjective optimization problems with heterogeneous objectives (HEMOPs). So far, however, only a few studies have been reported on addressing HE-MOPs, and most of them focus on biobjective problems with one fast objective and one slow objective. In this work, we aim to deal with HE-MOPs having more than two black-box and heterogeneous objectives. To this end, we develop a multiobjective Bayesian evolutionary optimization (BEO) approach to HE-MOPs that can alleviate search biases resulting from the different numbers of function evaluations allowed for the cheap and expensive objectives.</p>
<p><b>Bio: </b>Xilu Wang received the Ph.D. degree with the University of Surrey, Guildford, U.K., under the supervision of Prof. Y. Jin. She received the B.Sc. degree in electronic and information engineering from the Harbin Institute of Technology, Harbin, China, in 2016, and the M.Sc. degree in electronics and telecommunications engineering Xidian University, Xiâan, China, in 2018. </p>

<div style="height: 20px;"></div>
<p><b>Tilte:</b>Learning Improvement Representations to Accelerate Evolutionary Complex Multiobjective Optimization</p>
<p><b>Abstract: </b>Evolutionary algorithms are highly effective for solving complex optimization problems, especially those involving multiple objectives. However, their significant computational demands and inherent stochasticity can slow down convergence to global optima, particularly in intricate scenarios. In this talk, I will discuss our efforts to accelerate the convergence of complex multi-objective optimization problems through learning improvement representations. Our proposed methods involve training a neural model to learn performance improvement representations of solutions in various optimization contexts, including large-scale, dynamic, and constrained multi-objective optimization. By analyzing transitions between suboptimal and superior solutions, the model captures critical insights into performance improvements. We then design various learnable evolutionary generators guided by these learned improvement representations. These generators produce higher-quality offspring solutions by concurrently exploring the learned representation spaces. This approach accelerates the populationâs convergence toward global optimality, steering the search process in more promising directions and enhancing overall efficiency.</p>
<p><b>Bio: </b>Songbai Liu (Member IEEE) received the M.S. degree from Shenzhen University, China, in 2018. He received the Ph.D. degree from Department of Computer Sciences, City University of Hong Kong, in 2022. He is currently an assistant professor in College of Computer Science and Software Engineering, Shenzhen University. He has published over 20 papers in prestigious journals such as IEEE Transactions on Evolutionary Computation (IEEE TEVC), IEEE Transactions on Cybernetics (IEEE TCYB), IEEE Transactions on Systems, Man, and Cybernetics (IEEE TSMC), and IEEE Transactions on Emerging Topics in Computational Intelligence (IEEE TETCI). Additionally, he has served as a reviewer for these and other leading journals in the field of evolutionary computation. His research interests include evolutionary algorithms + machine learning, multiobjective optimization, and their applications.</p>

<div style="height: 20px;"></div>
<p><b>Tilte:</b> Solving Multi-solution Problems in Machine Learning via Evolutionary Computation</p>
<p><b>Abstract: </b>Machine learning (ML) methods have obtained great success across a number of practical applications and attracted growing interest. How to improve learning performance has emerged as a prominent research area. In ML, the identification of multiple optimal or near-optimal solutions/models (i.e., multi-solution characteristics) is a common preference of many users. Examples include finding all possible structures in a protein prediction problem or providing multiple-diagnostic methods in disease prediction. In this talk, I will discuss how evolutionary computation methods especially niching techniques and multimodal multi-objective optimization are used to find multiple optimal or near-optimal solutions/models for a learning task. The multi-solution characteristics of a learning task is emphasized and analyzed. Also, our talk will discuss key challenges and provide insights into potential emerging directions in this field.</p>
<p><b>Bio: </b> Peng Wang (Member IEEE) received the M.S. degree from Zhengzhou University, China, in 2019. He received the Ph.D. degree from the School of Engineering and Computer Science, Victoria University of Wellington, in 2023. He is currently an assistant professor in the school of Electrical and Information Engineering, Zhengzhou University. He has published over 10 papers in prestigious journals such as IEEE Transactions on Evolutionary Computation (IEEE TEVC), IEEE Transactions on Cybernetics (IEEE TCYB), and Pattern Recognition. Additionally, he has served as a reviewer for these and other leading journals in the field of feature selection and evolutionary computation. His current research interests include dimensionality reduction (mainly feature selection and feature construction for classification), evolutionary computation, and their applications.</p>

<div style="height: 20px;"></div>
<p>  <b>Tilte:</b>Evolutionary computation for identifying biomarkers of individual patients in cancer
Evolutionary computation for identifying biomarkers of individual patients in cancer
</p>
<p><b>Abstract: </b> With the advancement of high-throughput sequencing technology, there has been a significant increase in the volume of known cancer omics data, where many methods have been developed to identify potential biomarkers for mining the complex dynamics. As emerging artificial intelligence techniques, evolutionary computation has found extensive application in the identification of biomarkers. However, the high dimension and complex dynamics of biomarkers in omics data pose a big challenge to apply EC for mining cancer omics data. In this talk, I will discuss our efforts to identify predictive and prognostic biomarkers in cancer by combining multimodal optimization and multiobjective optimization and network science. On one hand, several algorithms (denoted MMPDNB and MMPDNB-RBM) based on a multimodal optimization mechanism and personalized dynamic network biomarker theory, which can provide multiple modules of personalized biomarkers and unveil their multi-modal properties of node and edge module biomarkers. On the other hand, weÂ proposedÂ multi-objectiveÂ optimization basedÂ structuralÂ networkÂ controlÂ principlesbyÂ consideringÂ minimumÂ driverÂ nodesÂ andÂ maximumÂ prior-knownÂ drug targetÂ information.Â Subsequently,Â several methods including LSCV-MCEA, LSCV-TSEA and SNCPDTsÂ wereÂ developedÂ byÂ adaptingÂ knowledge-embedded multitasking constrained multiobjective evolutionary algorithm.Â </p>
<p><b>Bio: </b>  Wei-Feng Guo (Member IEEE) is currently an assistant professor in the department of Electrical and Information Engineering, Zheng Zhou University. He obtained the PhD degree at the department of automation from Northwestern polytechnical university, China. He does researches in design of complex network and evolution computing algorithms and the applications to human cancer genomics. He has published over 20 papers in prestigious journals such as IEEE Transactions on Evolutionary Computation (IEEE TEVC), Nucleic Acids Research (NAR), and Briefings in bioinformatics (BIB). Additionally, he has served as a reviewer for these and other leading journals in the field of evolutionary computation and bioinformatics. 
</p>




<p>&nbsp;</p>
<h3><font color="#0000FF">Contact information of the organizers</font></h3>
<p>
<b>Prof. Jing Liang</b></br>
School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China</br>
<a href=âmailto:liangjing@zzu.edu.cnâ>Email:liangjing@zzu.edu.cn</a></br>
</p>  

<p>
<b>A/Prof. Caitong Yue</b></br>
School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China</br>
<a href=âmailto:zzuyuecaitong@163.comâ>Email:zzuyuecaitong@163.com</a></br>
</p>


<p>
<b>A/Prof. Kunjie Yu</b></br>
School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China</br>
<a href=âmailto:yukunjie@zzu.edu.cnâ>Email:yukunjie@zzu.edu.cn</a></br>
</p>


<p>
<b>Prof. Ying Bi</b></br>
School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China</br>
<a href=âmailto:yingbi@zzu.edu.cnâ>Email:yingbi@zzu.edu.cn</a></br>
</p>

<p>&nbsp;</p>
<h3><font color="#0000FF">Short bio of the organizers</font></h3>
<p>
<b>Jing Liang (Senior Member, IEEE and IEEE CIS) </b>received the B.E degree from Harbin Institute of Technology, China and the Ph.D. degree from Nanyang Technological University, Singapore, and her dissertation received the IEEE CIS Outstanding Ph.D. Dissertation Award. She is currently a Professor with the School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China.</p>

<p>Prof. Liang's research focuses mainly on computational intelligence, particularly intelligent optimization and evolutionary computation. She has published over 200 fully referred journal and international conference papers, including more than 200 SCI/EI papers and 59 JCR Q1 papers. Among them, 6 papers are ESI highly cited papers. Up to now, her Google citations are over 21000 and the h-index is 56. She ranks 26th among all researchers (the 3rd among females) over the world in Evolutionary Computation according to Google Scholar citations. She was awarded the Highly Cited Chinese Researcher by ELSEVIER in 2021-2022 and the World's Top 2% Scientists by Stanford in 2022.</p>

<p>One of her publications--Comprehensive learning particle swarm optimizer for global optimization of multimodal functions ranked the first among all most most-cited articles in the past decades in the field of Evolutionary Computation. This paper was cited more than 3800 times in a single article and was ranked first in the 'Classic Papers: Articles that have stood the test of time' released by Google Scholar in 2017. Prof. Liang has also designed a series of benchmark functions/problems for evaluating the performance of evolutionary computation algorithms. The proposed benchmark functions/problems have been widely used and recognized by researchers and scholars in 45 disciplines from 67 countries and regions around the world. This comprehensively demonstrates the contributions and influence of Prof. Liang's research to the computational intelligence field.</p>

<p>Prof. Liang served as an associate editor of IEEE Computational Intelligence Magazine, IEEE Transactions on Evolutionary Computation, IEEE Transactions on Systems Man and Cybernetics: Systems, and many other international journals. She won the IEEE Transactions on Evolutionary Computation (TEVC) Outstanding Associate Editor Award in 2019 and the Best Reviewer Award of the journal SCIENCE CHINA: Technological Science in 2021. She was the lead organizer of the "IEEE Student Branch of Zhengzhou University" founded in 2013. She served as Award Chair of 2021 IEEE International Conference on Advanced Robots and Mechatronics (IEEE ARM 2021), Co-organizer of Swarm Intelligence Symposium (SIS) in 2019 IEEE Symposium Series on Computational Intelligence (SSCI2019), Special Session Organizer of IEEE Congress on Evolutionary Computation (CEC) in 2005, 2013, 2014, 2015, 2018, 2019, 2020, 2021 and 2022. Prof. Liang has chaired many academic conferences and events, such as the Eighth Symposium on Evolutionary Computing and Learning and the International Symposium on Evolutionary Computing and Learning in Asia in 2022, Frontier Forum on Artificial Intelligence and Automation and the 15th CAA Young Scientist Forum in 2021, and Intelligent Simulation Optimization and Scheduling Zhengzhou Branch--The 3rd Symposium on Evolutionary Computation: Past, Present, Future in 2018.</p>

<p>
<b>Caitong Yue (Member, IEEE and IEEE CIS)</b> received the B.E. degree in bioengineering and the Ph.D. degree in control science and engineering from Zhengzhou University, Zhengzhou, China, in 2014 and 2020, respectively. He is currently an associate professor with the School of Electrical and Information Engineering at Zhengzhou University. His research interests include evolutionary computation, multimodal multiobjective optimization, pattern recognition, neural network, machine learning and sparse optimization.</p>

<p>He serves as a reviewer for several well-known JCR Q1 journals including IEEE Transactions on Evolutionary Computation (IF 16.497), IEEE Transactions on Cybernetics (IF 19.118), etc. He has received several research grants, e.g., the National Natural Science Foundation of China (NSFC) young project, China Postdoctoral Science Foundation, Zhengzhou University Young Talent Innovation Team Project, Henan Province Science and Technology Research Project, and postdoctoral research project of Henan Province. He has published more than 70 SCI/EI papers with 2600 Google citations. He has also published five technical reports, and participated in organizing five international algorithm competitions.</p>

<p>
<b>Kunjie Yu (Member, IEEE and IEEE CIS)</b> received the Ph.D. degree in control science and engineering from the East China University of Science and Technology, Shanghai, China, in 2017. Currently, he is an associate professor with the School of Electrical and Information Engineering, Zhengzhou University. His current research interests include evolutional computation, constrained optimization, multiobjective optimization, dynamic multiobjective optimization and their applications in chemical process, photovoltaic system, and energy system.</p>

<p>He serves as an Associate Editor for Swarm and Evolutionary Computation, and a reviewer for several well-known JCR Q1 journals including IEEE Transactions on Evolutionary Computation, IEEE Transactions on Cybernetics, etc. He has published more than 50 papers indexed by SCI, and the published papers have been cited more than 4000 times in Google Scholar, and 8 ESI highly cited papers. He has been selected as the Top Young Talent of Central Plains, the Natural Science Foundation for Outstanding Young Scholars of Henan Province, the Stanford University Top 2% of the World's Top Scientists 2022, and the Youth Promotion Project of Henan Province.</p>

<p>
<b>Ying Bi</b> is a distinguished professor with the School of Electrical and Information Engineering at Zhengzhou University. China. Her research focuses mainly on computer vision, image analysis, machine learning, deep learning, evolutionary computation, genetic programming, classification, feature learning, and transfer learning. She has published an authored book on genetic programming for image classification and over 50 papers in fully refereed journals and conferences in computer vision and evolutionary computation.</p>

<p>She has been serving as a workshop chair of IEEE CEC 2024, student affair co-chair of GECCO 2024, GECCO 2023, an organizing committee member of ECOLE 2022, IEEE CEC 2019 and Australasian AI 2018, an organizer of a workshop in IEEE ICDM 2023, IEEE ICDM 2022, IEEE ICDM 2021, the symposium in IEEE SSCI 2022, IEEE SSCI 2021, a special session in SSCI 2021 and a special session in IDEAL 2021, and a program committee member of over twenty international conferences including IJCAI, GECCO, IEEE CEC, IEEE SSCI, and Australasian AI. She was co-chair Poster session in IEEE CEC 2019. She is serving as a reviewer of over twenty international journals. She is a member of IEEE, IEEE Computational Intelligence Society (CIS) and ACM SIGEVO.</p>




<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p> 
</body>

</html>

<!--
000000 	000033 	000066 	000099 	0000CC 	0000FF
003300 	003333 	003366 	003399 	0033CC 	0033FF
006600 	006633 	006666 	006699 	0066CC 	0066FF
009900 	009933 	009966 	009999 	0099CC 	0099FF
00CC00 	00CC33 	00CC66 	00CC99 	00CCCC 	00CCFF
00FF00 	00FF33 	00FF66 	00FF99 	00FFCC 	00FFFF
 -->
